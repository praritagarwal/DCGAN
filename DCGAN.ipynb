{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project to build and train a DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 2.1.0\n",
      "keras version: 2.2.4-tf\n",
      "GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print('tensorflow version: {}'.format(tf.__version__))\n",
    "print('keras version: {}'.format(keras.__version__))\n",
    "print('GPU: {}'.format(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While in this project, we ultimately wish to train the GAN on the [lfw](https://www.tensorflow.org/datasets/catalog/lfw) dataset to make it generate human faces, we will start small and train it on the Fashion-MNIST for practice. Once that works, we will try to build upon our acquired knowledge to train on the lfw dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the Fashion-MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train, _), (_,_) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_train: (60000, 28, 28)\n",
      "max pixel value: 255\n",
      "min pixel value: 0\n"
     ]
    }
   ],
   "source": [
    "print('shape of X_train: {}'.format(X_train.shape))\n",
    "print('max pixel value: {}'.format(X_train.max()))\n",
    "print('min pixel value: {}'.format(X_train.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new pixel max: 1.0\n",
      "new pixel min: -1.0\n"
     ]
    }
   ],
   "source": [
    "# scale the pixel value to have max = 1 and min = -1\n",
    "max_px = X_train.max()\n",
    "min_px = X_train.min()\n",
    "A = 2/(max_px - min_px)\n",
    "B = -1*(max_px + min_px)/(max_px - min_px)\n",
    "X_train = A*X_train + B\n",
    "print('new pixel max: {}'.format(X_train.max()))\n",
    "print('new pixel min: {}'.format(X_train.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
