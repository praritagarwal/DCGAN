{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Reshape, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN():\n",
    "    def __init__(self, restore_scale = None):\n",
    "        \n",
    "        # restore_scale is the function to be used to restore the scale of images when\n",
    "        # displaying a sample of generated images\n",
    "        \n",
    "        self.generator = None\n",
    "        self.discriminator = None\n",
    "        self.GAN = None\n",
    "        \n",
    "        # function to be used to restore the scale of images\n",
    "        self.restore_scale = restore_scale\n",
    "        \n",
    "    # function to build a generator of given specifications\n",
    "    # Assumption: the first layer is a dense layer and \n",
    "    # the rest are transpose Convolutional layers\n",
    "    # list layers consists of a list of tuples except for \n",
    "    # the first entry which is a tuple: (num_units, activation) for the dense layer\n",
    "    # the second entry is tuple of two objects: the height and the width of \n",
    "    # the feature maps obtained from reshaping the output of the first layer\n",
    "    # the rest of the enteries are tuples: (num_units, kernel_size, stride, padding, activation) for\n",
    "    # the transpose convolutional layers\n",
    "    # if batch_normalization == True, a BatchNormalization layer will be included after \n",
    "    # every hidden layer except the first dense layer\n",
    "    # if batch_normalization == False and drop_prob!=0, then \n",
    "    # a dropout layer is added after every layer except the dense layer    \n",
    "    def build_generator(self, list_layers, coding_size = 100, batch_normalization = True,\n",
    "                        drop_prob = 0, kernel_initializer = 'glorot_uniform'):  \n",
    "        dense_units, dense_act = list_layers.pop(0)\n",
    "        reshape_x, reshape_y = list_layers.pop(0)\n",
    "        reshape_channels = int(dense_units/(reshape_x*reshape_y))\n",
    "    \n",
    "        generator = Sequential( name = 'generator')\n",
    "        generator.add(Dense(units=dense_units, activation = dense_act, \n",
    "                        input_shape=[coding_size], kernel_initializer = kernel_initializer))\n",
    "        generator.add(Reshape([reshape_x, reshape_y, reshape_channels]))\n",
    "        \n",
    "        for num_units, kernel_size, stride, padding, activation in list_layers:\n",
    "            if batch_normalization:\n",
    "                generator.add(BatchNormalization())\n",
    "            elif drop_prob!=0:\n",
    "                generator.add(Dropout(drop_prob))\n",
    "                \n",
    "            trans_conv = Conv2DTranspose(filters = num_units, kernel_size = kernel_size, \n",
    "                                         strides = stride, padding = padding, \n",
    "                                         activation = activation, \n",
    "                                         kernel_initializer = kernel_initializer)\n",
    "            generator.add(trans_conv)\n",
    "        \n",
    "        \n",
    "        self.generator = generator\n",
    "    \n",
    "    \n",
    "    # function to build a generator with given specifications\n",
    "    # list_layers consists of a list of tuples used to describe each convolutional layer\n",
    "    # tuples: (num_units, kernel_size, stride, padding, activation)\n",
    "    # if batch_normalization is True, then each layer is followed by \n",
    "    # a BatchNormalization layer\n",
    "    # if batch_normalization is False and drop_prob!=0, then each layer is followed by \n",
    "    # a dropout layer\n",
    "    def build_discriminator(self, list_layers, input_shape, batch_normalization = False, \n",
    "                        drop_prob = 0.3, kernel_initializer = 'glorot_uniform'):\n",
    "        \n",
    "        discriminator = Sequential( name = 'discriminator')\n",
    "        filters, kernel_size, stride, padding, activation = list_layers.pop(0) \n",
    "        \n",
    "        conv2d = Conv2D(filters = filters, kernel_size = kernel_size,\n",
    "                        strides = stride, padding = padding, \n",
    "                        activation = activation, input_shape = input_shape, \n",
    "                        kernel_initializer = kernel_initializer)\n",
    "        \n",
    "        discriminator.add(conv2d)\n",
    "    \n",
    "        for filters, kernel_size, stride, padding, activation  in list_layers:\n",
    "            \n",
    "            if batch_normalization:\n",
    "                discriminator.add(BatchNormalization())\n",
    "            elif drop_prob!=0:\n",
    "                discriminator.add(Dropout(drop_prob))\n",
    "        \n",
    "            conv2d = Conv2D(filters = filters, kernel_size = kernel_size,\n",
    "                            strides = stride, padding = padding, activation = activation,\n",
    "                            kernel_initializer = kernel_initializer)\n",
    "        \n",
    "            discriminator.add(conv2d)\n",
    "        \n",
    "        discriminator.add(Flatten())\n",
    "        discriminator.add(Dense(1, activation = 'sigmoid'))\n",
    "        \n",
    "        self.discriminator = discriminator\n",
    "        \n",
    "    def build_GAN(self, optimizer, loss = 'binary_crossentropy', metrics = ['accuracy']):\n",
    "        \n",
    "        '''function to build and compile the GAN '''\n",
    "        \n",
    "        if (not self.discriminator) or (not self.generator):\n",
    "            print('Error: Either the generator or the discriminator has not been built yet!')\n",
    "            return\n",
    "        \n",
    "        self.GAN = Sequential([self.generator, self.discriminator])\n",
    "        self.discriminator.compile(loss = loss , optimizer = optimizer, metrics = metrics)\n",
    "        self.discriminator.trainable = False\n",
    "        self.GAN.compile(loss = loss, optimizer = optimizer, metrics = metrics)\n",
    "    \n",
    "   \n",
    "    def train_gan(self, training_images, num_epochs = 2, batch_size = 32,\n",
    "                  coding_size = 100, num_plots = 10):\n",
    "        \n",
    "        '''function to train the GAN'''\n",
    "        \n",
    "        plot_after = int(num_epochs/num_plots) # num epochs after which \n",
    "                                           # to plot an image to \n",
    "                                           # track the evolution of the GAN \n",
    "            \n",
    "        # sample codings to track the evolution of the GAN        \n",
    "        sample_codings = tf.random.normal(shape = (10, coding_size)) \n",
    "        \n",
    "        idxs = tf.range(2*batch_size) # indices of the img_batch obtained from combining \n",
    "                                      # true images with generated images\n",
    "        for epoch in tf.range(num_epochs):\n",
    "            start = time.time()\n",
    "            batch_accuracy = []\n",
    "            for true_imgs in training_images:\n",
    "                # generate a set of random codings\n",
    "                codings = tf.random.normal(shape = (batch_size, coding_size))\n",
    "                # convert the codings into images\n",
    "                gan_imgs = self.generator(codings)\n",
    "                y_gan = tf.constant([[0.]]*batch_size)\n",
    "                \n",
    "                # mix the gan images with the true images\n",
    "                y_true = tf.constant([[1.]]*batch_size)\n",
    "                all_imgs = tf.concat([true_imgs, gan_imgs], axis = 0)\n",
    "                all_y = tf.concat([y_true, y_gan], axis = 0)\n",
    "                \n",
    "                # shuffle the set of mixed images\n",
    "                # shuffling the set of mixed images takes a large amount of time\n",
    "                # I therefore decided to not do it\n",
    "                # shuffled_idxs = tf.random.shuffle(idxs)\n",
    "                # shuffled_imgs = tf.gather(all_imgs, shuffled_idxs)\n",
    "                # shuffled_y = tf.gather(all_y, shuffled_idxs)\n",
    "                \n",
    "                # phase 1: train the discriminator\n",
    "                self.discriminator.trainable = True\n",
    "                #self.discriminator.train_on_batch(shuffled_imgs, shuffled_y)\n",
    "                self.discriminator.train_on_batch(all_imgs, all_y)\n",
    "                \n",
    "                #pred = self.discriminator(shuffled_imgs)\n",
    "                #_, acc = self.discriminator.evaluate(shuffled_imgs, shuffled_y, \n",
    "                #                                     batch_size = 2*batch_size, verbose = 0)\n",
    "                pred = self.discriminator(all_imgs)\n",
    "                _, acc = self.discriminator.evaluate(all_imgs, all_y, \n",
    "                                                     batch_size = 2*batch_size, verbose = 0)\n",
    "                batch_accuracy.append(acc)\n",
    "                # phase 2: train the generator on a new set of codings\n",
    "                new_codings = tf.random.normal(shape = (batch_size, coding_size))\n",
    "                self.discriminator.trainable = False\n",
    "                self.GAN.train_on_batch(codings, 1-y_gan)\n",
    "                \n",
    "            # evaluate the GAN's performance so far\n",
    "            mean_acc = tf.math.reduce_mean(tf.constant(batch_accuracy), axis = 0)\n",
    "            end = time.time()\n",
    "            time_taken = end - start\n",
    "            print_info = (epoch+1,num_epochs, time_taken, mean_acc)\n",
    "            print('\\repoch:{0:}/{1:}, time:{2: .2f}s, disc. accuracy:{3: .2f} '.format(*print_info), \n",
    "                  end = '', flush = True)\n",
    "            print('=', end = '')\n",
    "            \n",
    "            # plot the images produced by the GAN at different stages of training\n",
    "            if epoch%plot_after == 0:\n",
    "                sample_imgs = self.generator(sample_codings)\n",
    "                predictions = self.discriminator(sample_imgs)\n",
    "                # reshape the image if grayscale\n",
    "                _ ,height, width, channels = sample_imgs.shape\n",
    "                if channels == 1:\n",
    "                    sample_imgs = tf.reshape(sample_imgs,[-1, height, width])\n",
    "                # rescale the image pixels to be between 0 and 1\n",
    "                if self.restore_scale:\n",
    "                    sample_imgs = self.restore_scale(sample_imgs)\n",
    "                fig, ax = plt.subplots(figsize = (15, 5), ncols = 10 )\n",
    "                for col in range(10):\n",
    "                    ax[col].imshow(sample_imgs[col])\n",
    "                    ax[col].axis('off')\n",
    "                    ax[col].set_title('pred: {: .2f}'.format(predictions[col][0]))\n",
    "                plt.show() \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to convert this notebook into a python module, use the following in command line:\n",
    "\n",
    "``` ipython nbconvert --to python my_DCGAN_class.ipynb```\n",
    "\n",
    "This was suggested by Sarath Ak in the [this](https://stackoverflow.com/questions/52885901/how-to-save-python-script-as-py-file-on-jupyter-notebook/52886052) stackexchange post.\n",
    "\n",
    "``` ipython``` has been depricated. Use ```jupyter nbconvert --to python my_DCGAN_class.ipynb``` instead.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
